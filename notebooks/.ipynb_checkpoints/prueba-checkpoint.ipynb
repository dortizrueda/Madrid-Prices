{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31612ac5-0aca-4d91-9c82-1e819266e791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Cargando y preparando datos...\n",
      "üõ† Creando nuevas features...\n",
      "‚úÇÔ∏è Dividiendo datos en train (80%) y test (20%)...\n",
      "Tama√±o de los conjuntos:\n",
      "- Train: 9460 muestras\n",
      "- Test: 2366 muestras\n",
      "‚öôÔ∏è Configurando preprocesamiento...\n",
      "üß† Configurando modelos con par√°metros optimizados...\n",
      "üöÄ Iniciando entrenamiento...\n",
      "\n",
      "üîπ Entrenando ridge...\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "\n",
      "üîπ Entrenando random_forest...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "\n",
      "üîπ Entrenando xgboost...\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "\n",
      "üîó Creando modelo ensemble (RandomForest + XGBoost)...\n",
      "\n",
      "üìä Resultados Finales:\n",
      "\n",
      "RIDGE          \n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ Dataset  ‚îÇ RMSE         ‚îÇ R¬≤           ‚îÇ MAPE         ‚îÇ\n",
      "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "‚îÇ Train    ‚îÇ    931650.47 ‚îÇ       0.4308 ‚îÇ       0.8469 ‚îÇ\n",
      "‚îÇ Test     ‚îÇ    920793.07 ‚îÇ       0.4564 ‚îÇ       0.8352 ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      "Mejores par√°metros: {'model__alpha': 10000.0, 'model__fit_intercept': True}\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "RANDOM_FOREST  \n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ Dataset  ‚îÇ RMSE         ‚îÇ R¬≤           ‚îÇ MAPE         ‚îÇ\n",
      "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "‚îÇ Train    ‚îÇ    331208.27 ‚îÇ       0.9281 ‚îÇ       0.1308 ‚îÇ\n",
      "‚îÇ Test     ‚îÇ    449302.52 ‚îÇ       0.8706 ‚îÇ       0.1976 ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      "Mejores par√°metros: {'model__max_depth': 20, 'model__min_samples_leaf': 3, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "XGBOOST        \n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ Dataset  ‚îÇ RMSE         ‚îÇ R¬≤           ‚îÇ MAPE         ‚îÇ\n",
      "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "‚îÇ Train    ‚îÇ    228526.38 ‚îÇ       0.9658 ‚îÇ       0.1821 ‚îÇ\n",
      "‚îÇ Test     ‚îÇ    431975.24 ‚îÇ       0.8804 ‚îÇ       0.2046 ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      "Mejores par√°metros: {'model__learning_rate': 0.1, 'model__max_depth': 6, 'model__n_estimators': 200, 'model__reg_alpha': 0.1, 'model__reg_lambda': 0.1, 'model__subsample': 0.8}\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ENSEMBLE PERFORMANCE:\n",
      "Test RMSE: 430762.81\n",
      "Test R¬≤: 0.8810\n",
      "\n",
      "üîé An√°lisis de importancia de variables (Random Forest):\n",
      "\n",
      "Top 10 variables m√°s importantes:\n",
      "                     Feature  Importance\n",
      "32                   es_lujo    0.494906\n",
      "1                     metros    0.286197\n",
      "7     habitaciones_por_metro    0.061058\n",
      "12  zona_barrio-de-salamanca    0.050327\n",
      "5                    Latitud    0.025985\n",
      "4                 planta_num    0.017370\n",
      "6                   Longitud    0.013022\n",
      "24               zona_retiro    0.010341\n",
      "2               habitaciones    0.008607\n",
      "16             zona_chamberi    0.007471\n",
      "\n",
      "üíæ Importancia de variables guardada en 'importancia_variables.csv'\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Script mejorado de entrenamiento para modelos de predicci√≥n de precios de viviendas\n",
    "Con an√°lisis de resultados y feature engineering\n",
    "\"\"\"\n",
    "\n",
    "# ==================== CONFIGURACI√ìN INICIAL ====================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==================== CARGA Y PREPARACI√ìN DE DATOS ====================\n",
    "print(\"üîÑ Cargando y preparando datos...\")\n",
    "df = pd.read_csv(\"../data/datos_limpios_eda.csv\")\n",
    "\n",
    "# Filtrar outliers si existe la columna\n",
    "if 'outlier' in df.columns:\n",
    "    df = df[df['outlier'] == False]\n",
    "\n",
    "# Feature Engineering: Crear nuevas variables\n",
    "print(\"üõ† Creando nuevas features...\")\n",
    "df['precio_por_m2'] = df['PrecioActual']/df['metros']\n",
    "df['habitaciones_por_metro'] = df['habitaciones']/df['metros']\n",
    "df['es_lujo'] = df['PrecioActual'].apply(lambda x: 1 if x > 1000000 else 0)\n",
    "\n",
    "# Definir variables\n",
    "X = df.drop(columns=[\"PrecioActual\", \"precio_por_m2\"])  # Excluimos la target y derivadas\n",
    "y = df[\"PrecioActual\"]\n",
    "\n",
    "# ==================== TRAIN-TEST SPLIT ==================== \n",
    "print(\"‚úÇÔ∏è Dividiendo datos en train (80%) y test (20%)...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "print(f\"Tama√±o de los conjuntos:\")\n",
    "print(f\"- Train: {X_train.shape[0]} muestras\")\n",
    "print(f\"- Test: {X_test.shape[0]} muestras\")\n",
    "\n",
    "# ==================== PREPROCESAMIENTO ====================\n",
    "print(\"‚öôÔ∏è Configurando preprocesamiento...\")\n",
    "\n",
    "# Columnas num√©ricas y categ√≥ricas (actualizadas con nuevas features)\n",
    "num_cols = [\"PrecioAnterior\", \"metros\", \"habitaciones\", \"ba√±os\", \"planta_num\", \n",
    "            \"Latitud\", \"Longitud\", \"habitaciones_por_metro\"]\n",
    "cat_cols = [c for c in X.columns if c.startswith(('zona_', 'ascensor_', 'localizacion_',\n",
    "                                                 'reformado','piscina','tiene_ascensor','es_lujo'))]\n",
    "\n",
    "# Transformador de columnas\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', RobustScaler(), num_cols),\n",
    "    ('cat', 'passthrough', cat_cols)\n",
    "])\n",
    "\n",
    "# ==================== MODELOS MEJORADOS ====================\n",
    "print(\"üß† Configurando modelos con par√°metros optimizados...\")\n",
    "\n",
    "models = {\n",
    "    'ridge': {\n",
    "        'pipe': Pipeline([\n",
    "            ('prep', preprocessor),\n",
    "            ('model', Ridge(random_state=42))\n",
    "        ]),\n",
    "        'params': {\n",
    "            'model__alpha': np.logspace(0, 4, 20),\n",
    "            'model__fit_intercept': [True, False]\n",
    "        }\n",
    "    },\n",
    "    'random_forest': {\n",
    "        'pipe': Pipeline([\n",
    "            ('prep', preprocessor),\n",
    "            ('model', RandomForestRegressor(random_state=42))\n",
    "        ]),\n",
    "        'params': {\n",
    "            'model__n_estimators': [200],\n",
    "            'model__max_depth': [15, 20],  # Limitado para reducir overfitting\n",
    "            'model__min_samples_split': [2, 5],\n",
    "            'model__min_samples_leaf': [3, 5]\n",
    "        }\n",
    "    },\n",
    "    'xgboost': {\n",
    "        'pipe': Pipeline([\n",
    "            ('prep', preprocessor),\n",
    "            ('model', XGBRegressor(objective='reg:squarederror', random_state=42))\n",
    "        ]),\n",
    "        'params': {\n",
    "            'model__n_estimators': [200],\n",
    "            'model__learning_rate': [0.05, 0.1],\n",
    "            'model__max_depth': [6],\n",
    "            'model__subsample': [0.8, 1.0],\n",
    "            'model__reg_alpha': [0, 0.1],  # Regularizaci√≥n L1\n",
    "            'model__reg_lambda': [0, 0.1]  # Regularizaci√≥n L2\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# ==================== ENTRENAMIENTO ====================\n",
    "print(\"üöÄ Iniciando entrenamiento...\")\n",
    "results = {}\n",
    "best_models = {}\n",
    "\n",
    "for name, config in models.items():\n",
    "    print(f\"\\nüîπ Entrenando {name}...\")\n",
    "    \n",
    "    gs = GridSearchCV(\n",
    "        estimator=config['pipe'],\n",
    "        param_grid=config['params'],\n",
    "        cv=5,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    gs.fit(X_train, y_train)\n",
    "    best_models[name] = gs.best_estimator_\n",
    "    joblib.dump(gs.best_estimator_, f'mejor_modelo_{name}.pkl')\n",
    "    \n",
    "    # Evaluaci√≥n completa\n",
    "    train_pred = gs.predict(X_train)\n",
    "    test_pred = gs.predict(X_test)\n",
    "    \n",
    "    results[name] = {\n",
    "        'Train': {\n",
    "            'RMSE': mean_squared_error(y_train, train_pred, squared=False),\n",
    "            'R2': r2_score(y_train, train_pred),\n",
    "            'MAPE': mean_absolute_percentage_error(y_train, train_pred)\n",
    "        },\n",
    "        'Test': {\n",
    "            'RMSE': mean_squared_error(y_test, test_pred, squared=False),\n",
    "            'R2': r2_score(y_test, test_pred),\n",
    "            'MAPE': mean_absolute_percentage_error(y_test, test_pred)\n",
    "        },\n",
    "        'Mejores par√°metros': gs.best_params_\n",
    "    }\n",
    "\n",
    "# ==================== ENSEMBLE ====================\n",
    "print(\"\\nüîó Creando modelo ensemble (RandomForest + XGBoost)...\")\n",
    "ensemble = VotingRegressor([\n",
    "    ('rf', best_models['random_forest'].named_steps['model']),\n",
    "    ('xgb', best_models['xgboost'].named_steps['model'])\n",
    "])\n",
    "\n",
    "# Aplicar el mismo preprocesamiento\n",
    "preprocessed_train = best_models['random_forest'].named_steps['prep'].transform(X_train)\n",
    "ensemble.fit(preprocessed_train, y_train)\n",
    "\n",
    "# Evaluar ensemble\n",
    "ensemble_pred = ensemble.predict(best_models['random_forest'].named_steps['prep'].transform(X_test))\n",
    "ensemble_rmse = mean_squared_error(y_test, ensemble_pred, squared=False)\n",
    "ensemble_r2 = r2_score(y_test, ensemble_pred)\n",
    "\n",
    "# ==================== AN√ÅLISIS DE RESULTADOS ====================\n",
    "print(\"\\nüìä Resultados Finales:\")\n",
    "for model, metrics in results.items():\n",
    "    print(f\"\\n{model.upper():<15}\")\n",
    "    print(\"‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\")\n",
    "    print(\"‚îÇ Dataset  ‚îÇ RMSE         ‚îÇ R¬≤           ‚îÇ MAPE         ‚îÇ\")\n",
    "    print(\"‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\")\n",
    "    print(f\"‚îÇ Train    ‚îÇ {metrics['Train']['RMSE']:>12.2f} ‚îÇ {metrics['Train']['R2']:>12.4f} ‚îÇ {metrics['Train']['MAPE']:>12.4f} ‚îÇ\")\n",
    "    print(f\"‚îÇ Test     ‚îÇ {metrics['Test']['RMSE']:>12.2f} ‚îÇ {metrics['Test']['R2']:>12.4f} ‚îÇ {metrics['Test']['MAPE']:>12.4f} ‚îÇ\")\n",
    "    print(\"‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\")\n",
    "    print(f\"Mejores par√°metros: {metrics['Mejores par√°metros']}\")\n",
    "    print(\"-\"*70)\n",
    "\n",
    "print(f\"\\nENSEMBLE PERFORMANCE:\")\n",
    "print(f\"Test RMSE: {ensemble_rmse:.2f}\")\n",
    "print(f\"Test R¬≤: {ensemble_r2:.4f}\")\n",
    "\n",
    "# ==================== AN√ÅLISIS DE IMPORTANCIA DE VARIABLES ====================\n",
    "print(\"\\nüîé An√°lisis de importancia de variables (Random Forest):\")\n",
    "rf_model = best_models['random_forest'].named_steps['model']\n",
    "preprocessor = best_models['random_forest'].named_steps['prep']\n",
    "\n",
    "try:\n",
    "    # Obtener nombres de caracter√≠sticas despu√©s del preprocesamiento\n",
    "    num_features = num_cols  # RobustScaler no cambia nombres\n",
    "    cat_features = preprocessor.named_transformers_['cat'].get_feature_names_out(input_features=cat_cols)\n",
    "    all_features = np.concatenate([num_features, cat_features])\n",
    "    \n",
    "    # Crear DataFrame con importancia\n",
    "    feature_importances = pd.DataFrame({\n",
    "        'Feature': all_features,\n",
    "        'Importance': rf_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 10 variables m√°s importantes:\")\n",
    "    print(feature_importances.head(10))\n",
    "    \n",
    "    # Guardar importancia de variables\n",
    "    feature_importances.to_csv('importancia_variables.csv', index=False)\n",
    "    print(\"\\nüíæ Importancia de variables guardada en 'importancia_variables.csv'\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ö†Ô∏è Error al obtener importancia de variables: {str(e)}\")\n",
    "    print(\"Posible causa: El preprocesador modific√≥ el n√∫mero de caracter√≠sticas\")\n",
    "    print(f\"N√∫mero de columnas originales: {len(X_train.columns)}\")\n",
    "    print(f\"N√∫mero de importancias: {len(rf_model.feature_importances_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "428ee126-c6a5-4aa1-a5cf-2bc4592b73ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç An√°lisis Comparativo:\n",
      "\n",
      "1. üèÜ Modelo Ganador: RANDOM FOREST\n",
      "   - Menor RMSE (258,264.92 vs 281,518.01 de XGBoost)\n",
      "   - Mayor R¬≤ (0.9565 vs 0.9483 de XGBoost)\n",
      "   - Par√°metros √≥ptimos: 200 √°rboles con profundidad 20\n",
      "\n",
      "2. üìâ Desempe√±o de Ridge Regression:\n",
      "   - RMSE significativamente mayor (911,884.74)\n",
      "   - Bajo R¬≤ (0.4572) confirma limitaciones con datos no lineales\n",
      "\n",
      "3. üí° Recomendaciones de Implementaci√≥n:\n",
      "   - Usar Random Forest como modelo principal en producci√≥n\n",
      "   - Considerar XGBoost para casos que requieran mayor velocidad\n",
      "   - Monitorear regularmente el desempe√±o con nuevos datos\n",
      "\n",
      "4. üõ† Posibles Mejoras:\n",
      "   - Feature engineering adicional (interacciones entre variables)\n",
      "   - Ensamblar modelos con VotingRegressor\n",
      "   - Optimizaci√≥n bayesiana de hiperpar√°metros\n",
      "\n",
      "‚úÖ Entrenamiento completado. Modelos guardados en:\n",
      "['mejor_modelo_ridge.pkl', 'mejor_modelo_random_forest.pkl', 'mejor_modelo_xgboost.pkl']\n"
     ]
    }
   ],
   "source": [
    "# ==================== AN√ÅLISIS DE RESULTADOS ====================\n",
    "print(\"\\nüîç An√°lisis Comparativo:\")\n",
    "\n",
    "print(\"\\n1. üèÜ Modelo Ganador: RANDOM FOREST\")\n",
    "print(\"   - Menor RMSE (258,264.92 vs 281,518.01 de XGBoost)\")\n",
    "print(\"   - Mayor R¬≤ (0.9565 vs 0.9483 de XGBoost)\")\n",
    "print(\"   - Par√°metros √≥ptimos: 200 √°rboles con profundidad 20\")\n",
    "\n",
    "print(\"\\n2. üìâ Desempe√±o de Ridge Regression:\")\n",
    "print(\"   - RMSE significativamente mayor (911,884.74)\")\n",
    "print(\"   - Bajo R¬≤ (0.4572) confirma limitaciones con datos no lineales\")\n",
    "\n",
    "print(\"\\n3. üí° Recomendaciones de Implementaci√≥n:\")\n",
    "print(\"   - Usar Random Forest como modelo principal en producci√≥n\")\n",
    "print(\"   - Considerar XGBoost para casos que requieran mayor velocidad\")\n",
    "print(\"   - Monitorear regularmente el desempe√±o con nuevos datos\")\n",
    "\n",
    "print(\"\\n4. üõ† Posibles Mejoras:\")\n",
    "print(\"   - Feature engineering adicional (interacciones entre variables)\")\n",
    "print(\"   - Ensamblar modelos con VotingRegressor\")\n",
    "print(\"   - Optimizaci√≥n bayesiana de hiperpar√°metros\")\n",
    "\n",
    "print(\"\\n‚úÖ Entrenamiento completado. Modelos guardados en:\")\n",
    "print([f\"mejor_modelo_{name}.pkl\" for name in models.keys()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
