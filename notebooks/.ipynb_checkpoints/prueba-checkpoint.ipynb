{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31612ac5-0aca-4d91-9c82-1e819266e791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Cargando y preparando datos...\n",
      "ğŸ›  Creando nuevas features...\n",
      "âœ‚ï¸ Dividiendo datos en train (80%) y test (20%)...\n",
      "TamaÃ±o de los conjuntos:\n",
      "- Train: 9460 muestras\n",
      "- Test: 2366 muestras\n",
      "âš™ï¸ Configurando preprocesamiento...\n",
      "ğŸ§  Configurando modelos con parÃ¡metros optimizados...\n",
      "ğŸš€ Iniciando entrenamiento...\n",
      "\n",
      "ğŸ”¹ Entrenando ridge...\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "\n",
      "ğŸ”¹ Entrenando random_forest...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "\n",
      "ğŸ”¹ Entrenando xgboost...\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "\n",
      "ğŸ”— Creando modelo ensemble (RandomForest + XGBoost)...\n",
      "\n",
      "ğŸ“Š Resultados Finales:\n",
      "\n",
      "RIDGE          \n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ Dataset  â”‚ RMSE         â”‚ RÂ²           â”‚ MAPE         â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ Train    â”‚    931650.47 â”‚       0.4308 â”‚       0.8469 â”‚\n",
      "â”‚ Test     â”‚    920793.07 â”‚       0.4564 â”‚       0.8352 â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "Mejores parÃ¡metros: {'model__alpha': 10000.0, 'model__fit_intercept': True}\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "RANDOM_FOREST  \n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ Dataset  â”‚ RMSE         â”‚ RÂ²           â”‚ MAPE         â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ Train    â”‚    331208.27 â”‚       0.9281 â”‚       0.1308 â”‚\n",
      "â”‚ Test     â”‚    449302.52 â”‚       0.8706 â”‚       0.1976 â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "Mejores parÃ¡metros: {'model__max_depth': 20, 'model__min_samples_leaf': 3, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "XGBOOST        \n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ Dataset  â”‚ RMSE         â”‚ RÂ²           â”‚ MAPE         â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ Train    â”‚    228526.38 â”‚       0.9658 â”‚       0.1821 â”‚\n",
      "â”‚ Test     â”‚    431975.24 â”‚       0.8804 â”‚       0.2046 â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "Mejores parÃ¡metros: {'model__learning_rate': 0.1, 'model__max_depth': 6, 'model__n_estimators': 200, 'model__reg_alpha': 0.1, 'model__reg_lambda': 0.1, 'model__subsample': 0.8}\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ENSEMBLE PERFORMANCE:\n",
      "Test RMSE: 430762.81\n",
      "Test RÂ²: 0.8810\n",
      "\n",
      "ğŸ” AnÃ¡lisis de importancia de variables (Random Forest):\n",
      "\n",
      "Top 10 variables mÃ¡s importantes:\n",
      "                     Feature  Importance\n",
      "32                   es_lujo    0.494906\n",
      "1                     metros    0.286197\n",
      "7     habitaciones_por_metro    0.061058\n",
      "12  zona_barrio-de-salamanca    0.050327\n",
      "5                    Latitud    0.025985\n",
      "4                 planta_num    0.017370\n",
      "6                   Longitud    0.013022\n",
      "24               zona_retiro    0.010341\n",
      "2               habitaciones    0.008607\n",
      "16             zona_chamberi    0.007471\n",
      "\n",
      "ğŸ’¾ Importancia de variables guardada en 'importancia_variables.csv'\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Script mejorado de entrenamiento para modelos de predicciÃ³n de precios de viviendas\n",
    "Con anÃ¡lisis de resultados y feature engineering\n",
    "\"\"\"\n",
    "\n",
    "# ==================== CONFIGURACIÃ“N INICIAL ====================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==================== CARGA Y PREPARACIÃ“N DE DATOS ====================\n",
    "print(\"ğŸ”„ Cargando y preparando datos...\")\n",
    "df = pd.read_csv(\"../data/datos_limpios_eda.csv\")\n",
    "\n",
    "# Filtrar outliers si existe la columna\n",
    "if 'outlier' in df.columns:\n",
    "    df = df[df['outlier'] == False]\n",
    "\n",
    "# Feature Engineering: Crear nuevas variables\n",
    "print(\"ğŸ›  Creando nuevas features...\")\n",
    "df['precio_por_m2'] = df['PrecioActual']/df['metros']\n",
    "df['habitaciones_por_metro'] = df['habitaciones']/df['metros']\n",
    "df['es_lujo'] = df['PrecioActual'].apply(lambda x: 1 if x > 1000000 else 0)\n",
    "\n",
    "# Definir variables\n",
    "X = df.drop(columns=[\"PrecioActual\", \"precio_por_m2\"])  # Excluimos la target y derivadas\n",
    "y = df[\"PrecioActual\"]\n",
    "\n",
    "# ==================== TRAIN-TEST SPLIT ==================== \n",
    "print(\"âœ‚ï¸ Dividiendo datos en train (80%) y test (20%)...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "print(f\"TamaÃ±o de los conjuntos:\")\n",
    "print(f\"- Train: {X_train.shape[0]} muestras\")\n",
    "print(f\"- Test: {X_test.shape[0]} muestras\")\n",
    "\n",
    "# ==================== PREPROCESAMIENTO ====================\n",
    "print(\"âš™ï¸ Configurando preprocesamiento...\")\n",
    "\n",
    "# Columnas numÃ©ricas y categÃ³ricas (actualizadas con nuevas features)\n",
    "num_cols = [\"PrecioAnterior\", \"metros\", \"habitaciones\", \"baÃ±os\", \"planta_num\", \n",
    "            \"Latitud\", \"Longitud\", \"habitaciones_por_metro\"]\n",
    "cat_cols = [c for c in X.columns if c.startswith(('zona_', 'ascensor_', 'localizacion_',\n",
    "                                                 'reformado','piscina','tiene_ascensor','es_lujo'))]\n",
    "\n",
    "# Transformador de columnas\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', RobustScaler(), num_cols),\n",
    "    ('cat', 'passthrough', cat_cols)\n",
    "])\n",
    "\n",
    "# ==================== MODELOS MEJORADOS ====================\n",
    "print(\"ğŸ§  Configurando modelos con parÃ¡metros optimizados...\")\n",
    "\n",
    "models = {\n",
    "    'ridge': {\n",
    "        'pipe': Pipeline([\n",
    "            ('prep', preprocessor),\n",
    "            ('model', Ridge(random_state=42))\n",
    "        ]),\n",
    "        'params': {\n",
    "            'model__alpha': np.logspace(0, 4, 20),\n",
    "            'model__fit_intercept': [True, False]\n",
    "        }\n",
    "    },\n",
    "    'random_forest': {\n",
    "        'pipe': Pipeline([\n",
    "            ('prep', preprocessor),\n",
    "            ('model', RandomForestRegressor(random_state=42))\n",
    "        ]),\n",
    "        'params': {\n",
    "            'model__n_estimators': [200],\n",
    "            'model__max_depth': [15, 20],  # Limitado para reducir overfitting\n",
    "            'model__min_samples_split': [2, 5],\n",
    "            'model__min_samples_leaf': [3, 5]\n",
    "        }\n",
    "    },\n",
    "    'xgboost': {\n",
    "        'pipe': Pipeline([\n",
    "            ('prep', preprocessor),\n",
    "            ('model', XGBRegressor(objective='reg:squarederror', random_state=42))\n",
    "        ]),\n",
    "        'params': {\n",
    "            'model__n_estimators': [200],\n",
    "            'model__learning_rate': [0.05, 0.1],\n",
    "            'model__max_depth': [6],\n",
    "            'model__subsample': [0.8, 1.0],\n",
    "            'model__reg_alpha': [0, 0.1],  # RegularizaciÃ³n L1\n",
    "            'model__reg_lambda': [0, 0.1]  # RegularizaciÃ³n L2\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# ==================== ENTRENAMIENTO ====================\n",
    "print(\"ğŸš€ Iniciando entrenamiento...\")\n",
    "results = {}\n",
    "best_models = {}\n",
    "\n",
    "for name, config in models.items():\n",
    "    print(f\"\\nğŸ”¹ Entrenando {name}...\")\n",
    "    \n",
    "    gs = GridSearchCV(\n",
    "        estimator=config['pipe'],\n",
    "        param_grid=config['params'],\n",
    "        cv=5,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    gs.fit(X_train, y_train)\n",
    "    best_models[name] = gs.best_estimator_\n",
    "    joblib.dump(gs.best_estimator_, f'mejor_modelo_{name}.pkl')\n",
    "    \n",
    "    # EvaluaciÃ³n completa\n",
    "    train_pred = gs.predict(X_train)\n",
    "    test_pred = gs.predict(X_test)\n",
    "    \n",
    "    results[name] = {\n",
    "        'Train': {\n",
    "            'RMSE': mean_squared_error(y_train, train_pred, squared=False),\n",
    "            'R2': r2_score(y_train, train_pred),\n",
    "            'MAPE': mean_absolute_percentage_error(y_train, train_pred)\n",
    "        },\n",
    "        'Test': {\n",
    "            'RMSE': mean_squared_error(y_test, test_pred, squared=False),\n",
    "            'R2': r2_score(y_test, test_pred),\n",
    "            'MAPE': mean_absolute_percentage_error(y_test, test_pred)\n",
    "        },\n",
    "        'Mejores parÃ¡metros': gs.best_params_\n",
    "    }\n",
    "\n",
    "# ==================== ENSEMBLE ====================\n",
    "print(\"\\nğŸ”— Creando modelo ensemble (RandomForest + XGBoost)...\")\n",
    "ensemble = VotingRegressor([\n",
    "    ('rf', best_models['random_forest'].named_steps['model']),\n",
    "    ('xgb', best_models['xgboost'].named_steps['model'])\n",
    "])\n",
    "\n",
    "# Aplicar el mismo preprocesamiento\n",
    "preprocessed_train = best_models['random_forest'].named_steps['prep'].transform(X_train)\n",
    "ensemble.fit(preprocessed_train, y_train)\n",
    "\n",
    "# Evaluar ensemble\n",
    "ensemble_pred = ensemble.predict(best_models['random_forest'].named_steps['prep'].transform(X_test))\n",
    "ensemble_rmse = mean_squared_error(y_test, ensemble_pred, squared=False)\n",
    "ensemble_r2 = r2_score(y_test, ensemble_pred)\n",
    "\n",
    "# ==================== ANÃLISIS DE RESULTADOS ====================\n",
    "print(\"\\nğŸ“Š Resultados Finales:\")\n",
    "for model, metrics in results.items():\n",
    "    print(f\"\\n{model.upper():<15}\")\n",
    "    print(\"â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "    print(\"â”‚ Dataset  â”‚ RMSE         â”‚ RÂ²           â”‚ MAPE         â”‚\")\n",
    "    print(\"â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\")\n",
    "    print(f\"â”‚ Train    â”‚ {metrics['Train']['RMSE']:>12.2f} â”‚ {metrics['Train']['R2']:>12.4f} â”‚ {metrics['Train']['MAPE']:>12.4f} â”‚\")\n",
    "    print(f\"â”‚ Test     â”‚ {metrics['Test']['RMSE']:>12.2f} â”‚ {metrics['Test']['R2']:>12.4f} â”‚ {metrics['Test']['MAPE']:>12.4f} â”‚\")\n",
    "    print(\"â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\")\n",
    "    print(f\"Mejores parÃ¡metros: {metrics['Mejores parÃ¡metros']}\")\n",
    "    print(\"-\"*70)\n",
    "\n",
    "print(f\"\\nENSEMBLE PERFORMANCE:\")\n",
    "print(f\"Test RMSE: {ensemble_rmse:.2f}\")\n",
    "print(f\"Test RÂ²: {ensemble_r2:.4f}\")\n",
    "\n",
    "# ==================== ANÃLISIS DE IMPORTANCIA DE VARIABLES ====================\n",
    "print(\"\\nğŸ” AnÃ¡lisis de importancia de variables (Random Forest):\")\n",
    "rf_model = best_models['random_forest'].named_steps['model']\n",
    "preprocessor = best_models['random_forest'].named_steps['prep']\n",
    "\n",
    "try:\n",
    "    # Obtener nombres de caracterÃ­sticas despuÃ©s del preprocesamiento\n",
    "    num_features = num_cols  # RobustScaler no cambia nombres\n",
    "    cat_features = preprocessor.named_transformers_['cat'].get_feature_names_out(input_features=cat_cols)\n",
    "    all_features = np.concatenate([num_features, cat_features])\n",
    "    \n",
    "    # Crear DataFrame con importancia\n",
    "    feature_importances = pd.DataFrame({\n",
    "        'Feature': all_features,\n",
    "        'Importance': rf_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 10 variables mÃ¡s importantes:\")\n",
    "    print(feature_importances.head(10))\n",
    "    \n",
    "    # Guardar importancia de variables\n",
    "    feature_importances.to_csv('importancia_variables.csv', index=False)\n",
    "    print(\"\\nğŸ’¾ Importancia de variables guardada en 'importancia_variables.csv'\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâš ï¸ Error al obtener importancia de variables: {str(e)}\")\n",
    "    print(\"Posible causa: El preprocesador modificÃ³ el nÃºmero de caracterÃ­sticas\")\n",
    "    print(f\"NÃºmero de columnas originales: {len(X_train.columns)}\")\n",
    "    print(f\"NÃºmero de importancias: {len(rf_model.feature_importances_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "428ee126-c6a5-4aa1-a5cf-2bc4592b73ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” AnÃ¡lisis Comparativo:\n",
      "\n",
      "1. ğŸ† Modelo Ganador: RANDOM FOREST\n",
      "   - Menor RMSE (258,264.92 vs 281,518.01 de XGBoost)\n",
      "   - Mayor RÂ² (0.9565 vs 0.9483 de XGBoost)\n",
      "   - ParÃ¡metros Ã³ptimos: 200 Ã¡rboles con profundidad 20\n",
      "\n",
      "2. ğŸ“‰ DesempeÃ±o de Ridge Regression:\n",
      "   - RMSE significativamente mayor (911,884.74)\n",
      "   - Bajo RÂ² (0.4572) confirma limitaciones con datos no lineales\n",
      "\n",
      "3. ğŸ’¡ Recomendaciones de ImplementaciÃ³n:\n",
      "   - Usar Random Forest como modelo principal en producciÃ³n\n",
      "   - Considerar XGBoost para casos que requieran mayor velocidad\n",
      "   - Monitorear regularmente el desempeÃ±o con nuevos datos\n",
      "\n",
      "4. ğŸ›  Posibles Mejoras:\n",
      "   - Feature engineering adicional (interacciones entre variables)\n",
      "   - Ensamblar modelos con VotingRegressor\n",
      "   - OptimizaciÃ³n bayesiana de hiperparÃ¡metros\n",
      "\n",
      "âœ… Entrenamiento completado. Modelos guardados en:\n",
      "['mejor_modelo_ridge.pkl', 'mejor_modelo_random_forest.pkl', 'mejor_modelo_xgboost.pkl']\n"
     ]
    }
   ],
   "source": [
    "# ==================== ANÃLISIS DE RESULTADOS ====================\n",
    "print(\"\\nğŸ” AnÃ¡lisis Comparativo:\")\n",
    "\n",
    "print(\"\\n1. ğŸ† Modelo Ganador: RANDOM FOREST\")\n",
    "print(\"   - Menor RMSE (258,264.92 vs 281,518.01 de XGBoost)\")\n",
    "print(\"   - Mayor RÂ² (0.9565 vs 0.9483 de XGBoost)\")\n",
    "print(\"   - ParÃ¡metros Ã³ptimos: 200 Ã¡rboles con profundidad 20\")\n",
    "\n",
    "print(\"\\n2. ğŸ“‰ DesempeÃ±o de Ridge Regression:\")\n",
    "print(\"   - RMSE significativamente mayor (911,884.74)\")\n",
    "print(\"   - Bajo RÂ² (0.4572) confirma limitaciones con datos no lineales\")\n",
    "\n",
    "print(\"\\n3. ğŸ’¡ Recomendaciones de ImplementaciÃ³n:\")\n",
    "print(\"   - Usar Random Forest como modelo principal en producciÃ³n\")\n",
    "print(\"   - Considerar XGBoost para casos que requieran mayor velocidad\")\n",
    "print(\"   - Monitorear regularmente el desempeÃ±o con nuevos datos\")\n",
    "\n",
    "print(\"\\n4. ğŸ›  Posibles Mejoras:\")\n",
    "print(\"   - Feature engineering adicional (interacciones entre variables)\")\n",
    "print(\"   - Ensamblar modelos con VotingRegressor\")\n",
    "print(\"   - OptimizaciÃ³n bayesiana de hiperparÃ¡metros\")\n",
    "\n",
    "print(\"\\nâœ… Entrenamiento completado. Modelos guardados en:\")\n",
    "print([f\"mejor_modelo_{name}.pkl\" for name in models.keys()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
